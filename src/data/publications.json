[
  {
    "id": "add-2024",
    "title": "Automatic Differential Diagnosis using Transformer-Based Multi-Label Sequence Classification",
    "authors": ["Abu Adnan Sadi", "Mohammad Ashrafuzzaman Khan", "Lubaba Binte Saber"],
    "venue": "arXiv preprint arXiv:2408.15827",
    "date": "2024-08-28",
    "year": 2024,
    "thumbnail": "/assets/previews/add-preview.png",
    "citationCount": 1,
    "selected": true,
    "scholarUrl": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=jNtX0U4AAAAJ&citation_for_view=jNtX0U4AAAAJ:2osOgNQ5qMEC",
    "buttons": [
      { "kind": "toggle", "label": "ABS", "target": "abstract", "content": "As the field of artificial intelligence progresses, assistive technologies are becoming more widely used across all industries. The healthcare industry is no different, with numerous studies being done to develop assistive tools for healthcare professionals. Automatic diagnostic systems are one such beneficial tool that can assist with a variety of tasks, including collecting patient information, analyzing test results, and diagnosing patients. However, the idea of developing systems that can provide a differential diagnosis has been largely overlooked in most of these research studies. In this study, we propose a transformer-based approach for providing differential diagnoses based on a patient's age, sex, medical history, and symptoms. We use the DDXPlus dataset, which provides differential diagnosis information for patients based on 49 disease types. Firstly, we propose a method to process the tabular patient data from the dataset and engineer them into patient reports to make them suitable for our research. In addition, we introduce two data modification modules to diversify the training data and consequently improve the robustness of the models. We approach the task as a multi-label classification problem and conduct extensive experiments using four transformer models. All the models displayed promising results by achieving over 97% F1 score on the held-out test set. Moreover, we design additional behavioral tests to get a broader understanding of the models. In particular, for one of our test cases, we prepared a custom test set of 100 samples with the assistance of a doctor. The results on the custom set showed that our proposed data modification modules improved the model's generalization capabilities. We hope our findings will provide future researchers with valuable insights and inspire them to develop reliable systems for automatic differential diagnosis." },
      { "kind": "toggle", "label": "BIB", "target": "bibtex", "content": "@article{sadi2024automatic,\ntitle = {Automatic Differential Diagnosis using Transformer-Based Multi-Label Sequence Classification}, \nauthor = {Sadi, Abu Adnan and Khan, Mohammad Ashrafuzzaman and Saber, Lubaba Binte}, \njournal = {arXiv preprint arXiv:2408.15827}, \nyear = {2024}, \ndoi = {https://doi.org/10.48550/arXiv.2408.15827}\n}" },
      { "kind": "asset", "label": "PDF", "path": "/assets/pubs/add-2024-preprint.pdf" },
      { "kind": "link", "label": "DEMO", "href": "https://huggingface.co/spaces/AdnanSadi/Differential-Diagnosis-Tool" }
    ]
  },
  {
    "id": "conf-plant-2024",
    "title": "A Comparative Study on Plant Diseases Using Object Detection Models",
    "authors": ["Abu Adnan Sadi", "Ziaul Hossain", "Ashfaq Uddin Ahmed", "Md Tazin Morshed Shad"],
    "venue": "Science and Information Conference",
    "date": "2024-06-20",
    "year": 2024,
    "thumbnail": "/assets/previews/conf-plant-2024-preview.png",
    "citationCount": 1,
    "selected": false,
    "scholarUrl": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=jNtX0U4AAAAJ&citation_for_view=jNtX0U4AAAAJ:9yKSN-GCB0IC",
    "buttons": [
      { "kind": "toggle", "label": "ABS", "target": "abstract", "content": "Plant diseases are the most widespread and significant hazard to ‘Precision Agriculture’. With early detection and analysis of diseases, the successful yield of cultivation can be increased; therefore, this process is regarded as a critical event. Unfortunately, manual observation-based detection method is error-prone, hard, and costly. Automation in identifying plant diseases is extremely beneficial because it saves time and manpower. Applying a neural network-based solution can detect disease symptoms at an early stage and facilitate the process of taking preventive or reactive measures. There have been various deep learning-based solutions, which were developed using lengthy training/testing cycles with large datasets. This study aims to investigate the suitability of computer vision-based approaches for this purpose. A comparative study has been performed using recently proposed object detection models such as YOLOv5, YOLOX, Scaled Yolov4, and SSD. A tailored version of the “PlantVillage” and “PlantDoc” datasets was used in the Indian sub-continent context, which included plant disease classes related to Potato, Corn, and Tomato plants. This study provides a detailed comparison between these object detection models and summarizes the suitability of these models for different cases. This paper can be useful for prospective researchers to decide which object detection models could be used for a specific scenario of Plant Disease Detection."},
      { "kind": "toggle", "label": "BIB", "target": "bibtex", "content": "@inproceedings{sadi2024comparative, \ntitle = {A Comparative Study on Plant Diseases Using Object Detection Models}, \nauthor = {Sadi, Abu Adnan and Hossain, Ziaul and Ahmed, Ashfaq Uddin and Shad, Md Tazin Morshed}, \nbooktitle = {Science and Information Conference}, \npages = {419--438}, \nyear = {2024}, \norganization = {Springer}, \ndoi = {https://doi.org/10.1007/978-3-031-62269-4_29} \n}"},
      { "kind": "asset", "label": "PDF", "path": "/assets/pubs/conf-plant-2024.pdf" },
      { "kind": "link", "label": "CODE", "href": "https://github.com/Adnan-Sadi/Plant-Disease-Detection-YOLO" }
    ]
  },
  {
    "id": "jour-vispol-2023",
    "title": "An end-to-end pollution analysis and detection system using artificial intelligence and object detection algorithms",
    "authors": ["Md Yearat Hossain", "Ifran Rahman Nijhum", "Md Tazin Morshed Shad", "Abu Adnan Sadi", "Md Mahmudul Kabir Peyal", "Rashedur M Rahman"],
    "venue": "Decision Analytics Journal",
    "date": "2023-09-01",
    "year": 2023,
    "thumbnail": "/assets/previews/vispol-2023-preview.jpg",
    "citationCount": 10,
    "selected": true,
    "scholarUrl": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=jNtX0U4AAAAJ&citation_for_view=jNtX0U4AAAAJ:u5HHmVD_uO8C",
    "buttons": [
      { "kind": "toggle", "label": "ABS", "target": "abstract", "content": "Environmental pollution is generally a by-product of various human activities. Researchers have studied the dangers and harmful effects of pollutants and environmental pollution for centuries, and many necessary steps have been taken. Modern solutions are being constantly developed to tackle these issues efficiently. Visual pollution analysis and detection is a relatively less studied subject, even though it significantly impacts our daily lives. Building automatic pollution or pollutants detection systems has become increasingly popular due to the modern development of advanced artificial intelligence systems. Although some advances have been made, automated pollution detection is not well-researched or fully understood. This study demonstrates how various object detection models could identify such environmental pollutants and how end-to-end applications can analyze the findings. We trained our dataset on three popular object detection models, YOLOv5, Faster R-CNN (Region-based Convolutional Neural Network), and EfficientDet, and compared their performances. The best Mean Average Precision (mAP) score of 0.85 was achieved by the You Only Look Once (YOLOv5) model using its inbuilt augmentation techniques. Then we built a minimal Android application, using which volunteers or authorities could capture and send images along with their Global Positioning System (GPS) coordinates that might contain visual pollutants. These images and coordinates are stored in the cloud and later used by our local server. The local server utilizes the best-trained visual pollution detection model. It generates heat maps of particular locations, visualizing the condition of visual pollution based on the data stored in the cloud. Along with the heat map, our analysis system provides visual analytics like bar charts and pie charts to summarize a region’s condition. In addition, we used Active Learning and Incremental Learning methods to utilize the newly collected dataset by building a semi-autonomous annotation and model upgrading system. This also addresses the data scarcity problem associated with further research on visual pollution."},
      { "kind": "toggle", "label": "BIB", "target": "bibtex", "content": "@article{vispol2023, \ntitle = {An end-to-end pollution analysis and detection system using artificial intelligence and object detection algorithms}, \nauthor = {Hossain, Md Yearat and Nijhum, Ifran Rahman and Shad, Md Tazin Morshed and Sadi, Abu Adnan and Peyal, Md Mahmudul Kabir and Rahman, Rashedur M}, \n journal = {Decision Analytics Journal}, \nvolume = {8}, \npages = {100283}, \nyear = {2023}, \npublisher = {Elsevier}, \ndoi = {https://doi.org/10.1016/j.dajour.2023.100283} \n}"},
      { "kind": "asset", "label": "PDF", "path": "/assets/pubs/vispol-2023.pdf" },
      { "kind": "link", "label": "DATASET", "href": "https://www.kaggle.com/datasets/yearathossain/visual-pollution-dhaka-streets" }
    ]
  },
  {
    "id": "lmfloss-preprint-2022",
    "title": "LMFLOSS: A Hybrid Loss For Imbalanced Medical Image Classification",
    "authors": ["Abu Adnan Sadi", "Labib Chowdhury", "Nusrat Jahan", "Mohammad Newaz Sharif Rafi", "Radeya Chowdhury", "Faisal Ahamed Khan", "Nabeel Mohammed"],
    "venue": "arXiv preprint arXiv:2212.12741",
    "date": "2022-12-24",
    "year": 2022,
    "thumbnail": "/assets/previews/lmfloss-preview.png",
    "citationCount": 21,
    "selected": true,
    "scholarUrl": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=jNtX0U4AAAAJ&citation_for_view=jNtX0U4AAAAJ:u-x6o8ySG0sC",
    "buttons": [
      { "kind": "toggle", "label": "ABS", "target": "abstract", "content": "With advances in digital technology, the classification of medical images has become a crucial step for image-based clinical decision support systems. Automatic medical image classification represents a pivotal domain where the use of AI holds the potential to create a significant social impact. However, several challenges act as obstacles to the development of practical and effective solutions. One of these challenges is the prevalent class imbalance problem in most medical imaging datasets. As a result, existing AI techniques, particularly deep-learning-based methodologies, often underperform in such scenarios. In this study, we propose a novel framework called Large Margin aware Focal (LMF) loss to mitigate the class imbalance problem in medical imaging. The LMF loss represents a linear combination of two loss functions optimized by two hyperparameters. This framework harnesses the distinct characteristics of both loss functions by enforcing wider margins for minority classes while simultaneously emphasizing challenging samples found in the datasets. We perform rigorous experiments on three neural network architectures and with four medical imaging datasets. We provide empirical evidence that our proposed framework consistently outperforms other baseline methods, showing an improvement of 2%-9% in macro-f1 scores. Through class-wise analysis of f1 scores, we also demonstrate how the proposed framework can significantly improve performance for minority classes. The results of our experiments show that our proposed framework can perform consistently well across different architectures and datasets. Overall, our study demonstrates a simple and effective approach to addressing the class imbalance problem in medical imaging datasets. We hope our work will inspire new research toward a more generalized approach to medical image classification."},
      { "kind": "toggle", "label": "BIB", "target": "bibtex", "content": "@article{LMFloss2022, \ntitle = {LMFLOSS: A Hybrid Loss For Imbalanced Medical Image Classification}, \nauthor = {Sadi, Abu Adnan and Chowdhury, Labib and Jahan, Nusrat and Rafi, Mohammad Newaz Sharif and Chowdhury, Radeya and Khan, Faisal Ahamed and Mohammed, Nabeel}, \nyear = {2022}, \njournal = {arXiv preprint arXiv:2212.12741}, \ndoi = {https://doi.org/10.48550/arXiv.2212.12741} \n}" },
      { "kind": "asset", "label": "PDF", "path": "/assets/pubs/lmfloss-2022-preprint.pdf" },
      { "kind": "link", "label": "CODE", "href": "https://github.com/Adnan-Sadi/LMFLOSS" }
    ]
  },
  {
    "id": "conf-vispol-2021",
    "title": "Visual Pollution Detection Using Google Street View and YOLO",
    "authors": ["Md Yearat Hossain", "Ifran Rahman Nijhum", "Abu Adnan Sadi", "Md Tazin Morshed Shad", "Rashedur M Rahman"],
    "venue": "2021 IEEE 12th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)",
    "date": "2021-12-01",
    "year": 2021,
    "thumbnail": "/assets/previews/vispol-2021-preview.jpg",
    "citationCount": 9,
    "selected": false,
    "scholarUrl": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=jNtX0U4AAAAJ&citation_for_view=jNtX0U4AAAAJ:d1gkVwhDpl0C",
    "buttons": [
      { "kind": "toggle", "label": "ABS", "target": "abstract", "content": "In recent years, visual pollution has become a major concern in rapidly rising cities. This research deals with detecting visual pollutants from the street images collected using Google Street View. For this experiment, we chose the streets of Dhaka, the capital city of Bangladesh, to build our image dataset, mainly because Dhaka was ranked recently as one of the most polluted cities in the world. However, the methods shown in this study can be applied to images of any city around the world and would produce close to a similar output. Throughout this study, we tried to portray the possible utilisation of Google Street View in building datasets and how this data can be used to solve environmental pollution with the help of deep learning. The image dataset was created manually by taking screenshots from various angles of every street view with visual pollutants in the frame. The images were then manually annotated using CVAT and were fed into the model for training. For the detection, we have used the object detection model YOLOv5 to detect all the visual pollutants present in the image. Finally, we evaluated the results achieved from this study and gave direction of using the outcome from this study in different domains."},
      { "kind": "toggle", "label": "BIB", "target": "bibtex", "content": "@inproceedings{vispol2021, \ntitle = {Visual Pollution Detection Using Google Street View and YOLO}, \nauthor = {Hossain, Md Yearat and Nijhum, Ifran Rahman and Sadi, Abu Adnan and Shad, Md Tazin Morshed and Rahman, Rashedur M}, \nbooktitle = {2021 IEEE 12th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)}, \npages = {0433--0440}, \nyear = {2021}, \norganization = {IEEE}, \ndoi = {10.1109/UEMCON53757.2021.9666654} \n}"},
      { "kind": "asset", "label": "PDF", "path": "/assets/pubs/vispol-2021.pdf" },
      { "kind": "link", "label": "DATASET", "href": "https://www.kaggle.com/datasets/yearathossain/visual-pollution-dhaka-streets" }
    ]
  }
]
